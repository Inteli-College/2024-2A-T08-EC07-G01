{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de classificação (S_GROUP_ID_1)\n",
    "\n",
    "A seguir, apresentamos os testes realizados com os modelos de classificação durante esta Sprint. O objetivo desses modelos é prever, após a detecção de uma falha no carro, quais tipos de falhas são mais prováveis de ocorrer. Para isso, cada tipo de falha é abordado por um modelo binário. Nesta Sprint, concentramos nossos esforços na avaliação do desempenho do modelo para a classe \"S_GROUP_ID_1\", buscando identificar o modelo com a melhor performance. Com base nos resultados obtidos, planejamos aplicar os insights e aprimoramentos para os modelos das outras classes existentes.\n",
    "\n",
    "Para conduzir os testes e comparar o desempenho dos diferentes modelos, utilizamos dois conjuntos de dados distintos. O primeiro conjunto de dados não incluiu as informações de torques fornecidas pelo parceiro, enquanto o segundo conjunto incorporou esses dados para treinar e aplicar o modelo. \n",
    "\n",
    "O processo de testes e as análises realizadas são detalhados a seguir, junto com as considerações e conclusões derivadas desses experimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,GRU, Dropout, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste sem dados de torque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, detalhamos os testes realizados utilizando redes neurais recorrentes LSTM e GRU nos dataframe sem dados de torque. O funcionamento dessas técnicas foi explicado em profundidade na documentação da Sprint 2, onde elas foram aplicadas ao modelo principal. Devido ao seu bom desempenho nessa etapa anterior, decidimos iniciar os testes desta Sprint utilizando essas RNNs como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        4\n",
       "3        2\n",
       "4        1\n",
       "        ..\n",
       "40149    4\n",
       "40150    0\n",
       "40151    4\n",
       "40152    2\n",
       "40153    2\n",
       "Name: S_GROUP_ID_1, Length: 40154, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregamento do dataframe\n",
    "df = pd.read_csv(\"../../data/Merge_Falhas_Resultados.csv\")\n",
    "df[\"S_GROUP_ID_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "40149    1\n",
       "40150    0\n",
       "40151    1\n",
       "40152    1\n",
       "40153    1\n",
       "Name: S_GROUP_ID_1, Length: 40154, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converter a coluna para binário\n",
    "df['S_GROUP_ID_1'] = (df['S_GROUP_ID_1'] > 0).astype(int)\n",
    "df['S_GROUP_ID_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as features (X) e o target (y)\n",
    "X = df.drop(columns=['S_GROUP_ID_1', 'KNR'])  # 'KNR' é apenas um identificador, então deve ser removido\n",
    "y = df['S_GROUP_ID_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em dados de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte X_train e X_test para arrays NumPy.\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reestrutura X_train e X_test para ter 3 dimensões.\n",
    "# A nova forma do array será (n_samples, n_features, 1)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\Documents\\GitHub\\2024-2A-T08-EC07-G01\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo com LSTM\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model_1.add(LSTM(50, activation='relu'))\n",
    "model_1.add(Dense(1))\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 32ms/step - loss: 300.8056 - val_loss: 2.7628\n",
      "Epoch 2/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - loss: 1.0809 - val_loss: 0.4644\n",
      "Epoch 3/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - loss: 0.4524 - val_loss: 0.4176\n",
      "Epoch 4/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - loss: 0.3700 - val_loss: 0.3696\n",
      "Epoch 5/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - loss: 0.3308 - val_loss: 0.5008\n",
      "Epoch 6/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - loss: 0.4190 - val_loss: 0.3706\n",
      "Epoch 7/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - loss: 0.3302 - val_loss: 0.3112\n",
      "Epoch 8/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - loss: 0.2777 - val_loss: 0.3475\n",
      "Epoch 9/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 63ms/step - loss: 0.3139 - val_loss: 0.2674\n",
      "Epoch 10/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - loss: 0.2692 - val_loss: 0.2564\n",
      "Epoch 11/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - loss: 2.9506 - val_loss: 0.2641\n",
      "Epoch 12/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - loss: 0.2790 - val_loss: 0.2499\n",
      "Epoch 13/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - loss: 0.2667 - val_loss: 0.2456\n",
      "Epoch 14/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - loss: 0.2669 - val_loss: 0.2466\n",
      "Epoch 15/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.2772 - val_loss: 0.3059\n",
      "Epoch 16/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.2785 - val_loss: 0.2422\n",
      "Epoch 17/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - loss: 0.2785 - val_loss: 0.2795\n",
      "Epoch 18/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 69ms/step - loss: 0.2716 - val_loss: 0.2432\n",
      "Epoch 19/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - loss: 0.2703 - val_loss: 0.2483\n",
      "Epoch 20/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 112ms/step - loss: 0.2743 - val_loss: 0.2682\n",
      "Epoch 21/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 84ms/step - loss: 0.2705 - val_loss: 0.3142\n",
      "Epoch 22/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.2733 - val_loss: 0.2393\n",
      "Epoch 23/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 53ms/step - loss: 0.2736 - val_loss: 0.2352\n",
      "Epoch 24/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - loss: 0.2604 - val_loss: 0.2408\n",
      "Epoch 25/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - loss: 0.2605 - val_loss: 0.2395\n",
      "Epoch 26/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 53ms/step - loss: 0.2677 - val_loss: 0.2420\n",
      "Epoch 27/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 56ms/step - loss: 0.2617 - val_loss: 0.3105\n",
      "Epoch 28/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - loss: 0.2610 - val_loss: 0.2859\n",
      "Epoch 29/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.2607 - val_loss: 0.2358\n",
      "Epoch 30/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step - loss: 0.2549 - val_loss: 0.2571\n",
      "Epoch 31/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - loss: 0.2509 - val_loss: 0.2341\n",
      "Epoch 32/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - loss: 0.2532 - val_loss: 0.2478\n",
      "Epoch 33/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 57ms/step - loss: 0.2493 - val_loss: 0.2369\n",
      "Epoch 34/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - loss: 0.2444 - val_loss: 0.2335\n",
      "Epoch 35/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 57ms/step - loss: 0.2438 - val_loss: 0.2355\n",
      "Epoch 36/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - loss: 0.2434 - val_loss: 0.2349\n",
      "Epoch 37/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - loss: 0.2393 - val_loss: 0.2331\n",
      "Epoch 38/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 62ms/step - loss: 0.2396 - val_loss: 0.3991\n",
      "Epoch 39/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 65ms/step - loss: 0.2392 - val_loss: 0.2341\n",
      "Epoch 40/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - loss: 0.2322 - val_loss: 0.2335\n",
      "Epoch 41/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - loss: 0.2321 - val_loss: 0.2332\n",
      "Epoch 42/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 78ms/step - loss: 0.2343 - val_loss: 0.2351\n",
      "Epoch 43/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - loss: 0.2335 - val_loss: 0.2328\n",
      "Epoch 44/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 75ms/step - loss: 0.2334 - val_loss: 0.2323\n",
      "Epoch 45/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 85ms/step - loss: 0.2327 - val_loss: 0.2341\n",
      "Epoch 46/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - loss: 0.2329 - val_loss: 0.2371\n",
      "Epoch 47/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.2318 - val_loss: 0.2338\n",
      "Epoch 48/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 79ms/step - loss: 0.2323 - val_loss: 0.2326\n",
      "Epoch 49/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - loss: 0.2315 - val_loss: 0.2332\n",
      "Epoch 50/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 83ms/step - loss: 0.2321 - val_loss: 0.2323\n",
      "Epoch 51/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - loss: 0.2322 - val_loss: 0.2313\n",
      "Epoch 52/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 43ms/step - loss: 0.2314 - val_loss: 0.2319\n",
      "Epoch 53/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 62ms/step - loss: 0.2307 - val_loss: 0.2313\n",
      "Epoch 54/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 57ms/step - loss: 0.2306 - val_loss: 0.2321\n",
      "Epoch 55/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 56ms/step - loss: 0.2303 - val_loss: 0.2305\n",
      "Epoch 56/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - loss: 0.2305 - val_loss: 0.2305\n",
      "Epoch 57/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.2305 - val_loss: 0.2308\n",
      "Epoch 58/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.2300 - val_loss: 0.2310\n",
      "Epoch 59/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.2283 - val_loss: 0.2308\n",
      "Epoch 60/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 60ms/step - loss: 0.2304 - val_loss: 0.2339\n",
      "Epoch 61/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.2299 - val_loss: 0.2307\n",
      "Epoch 62/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 71ms/step - loss: 0.2284 - val_loss: 0.2299\n",
      "Epoch 63/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.2295 - val_loss: 0.2294\n",
      "Epoch 64/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 92ms/step - loss: 0.2296 - val_loss: 0.2302\n",
      "Epoch 65/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 95ms/step - loss: 0.2300 - val_loss: 0.2305\n",
      "Epoch 66/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 93ms/step - loss: 0.2287 - val_loss: 0.2320\n",
      "Epoch 67/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 96ms/step - loss: 0.2304 - val_loss: 0.2310\n",
      "Epoch 68/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 100ms/step - loss: 0.2294 - val_loss: 0.2314\n",
      "Epoch 69/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 82ms/step - loss: 0.2384 - val_loss: 0.2357\n",
      "Epoch 70/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - loss: 0.2513 - val_loss: 0.2421\n",
      "Epoch 71/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 65ms/step - loss: 0.2353 - val_loss: 0.2352\n",
      "Epoch 72/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 81ms/step - loss: 0.2347 - val_loss: 0.2380\n",
      "Epoch 73/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 81ms/step - loss: 0.2528 - val_loss: 0.2356\n",
      "Epoch 74/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 69ms/step - loss: 0.2379 - val_loss: 0.2354\n",
      "Epoch 75/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - loss: 0.2360 - val_loss: 0.2351\n",
      "Epoch 76/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 87ms/step - loss: 0.2354 - val_loss: 0.2352\n",
      "Epoch 77/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2341 - val_loss: 0.2360\n",
      "Epoch 78/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 87ms/step - loss: 0.2365 - val_loss: 0.2348\n",
      "Epoch 79/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 87ms/step - loss: 0.2344 - val_loss: 0.2348\n",
      "Epoch 80/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 99ms/step - loss: 0.2357 - val_loss: 0.2345\n",
      "Epoch 81/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 92ms/step - loss: 0.2356 - val_loss: 0.2345\n",
      "Epoch 82/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 91ms/step - loss: 0.2397 - val_loss: 0.2422\n",
      "Epoch 83/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 110ms/step - loss: 0.2407 - val_loss: 0.2352\n",
      "Epoch 84/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 116ms/step - loss: 0.2352 - val_loss: 0.2372\n",
      "Epoch 85/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 109ms/step - loss: 0.2407 - val_loss: 0.2348\n",
      "Epoch 86/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 102ms/step - loss: 0.2350 - val_loss: 0.2343\n",
      "Epoch 87/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 88ms/step - loss: 0.2339 - val_loss: 0.2340\n",
      "Epoch 88/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.3158 - val_loss: 0.2350\n",
      "Epoch 89/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 82ms/step - loss: 0.2387 - val_loss: 0.2349\n",
      "Epoch 90/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 88ms/step - loss: 0.2359 - val_loss: 0.2365\n",
      "Epoch 91/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 89ms/step - loss: 0.2363 - val_loss: 0.2348\n",
      "Epoch 92/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2374 - val_loss: 0.2367\n",
      "Epoch 93/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2360 - val_loss: 0.2348\n",
      "Epoch 94/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 94ms/step - loss: 0.2353 - val_loss: 0.2346\n",
      "Epoch 95/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 106ms/step - loss: 0.2348 - val_loss: 0.2351\n",
      "Epoch 96/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 96ms/step - loss: 0.2357 - val_loss: 0.2353\n",
      "Epoch 97/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 107ms/step - loss: 0.2332 - val_loss: 0.2371\n",
      "Epoch 98/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 113ms/step - loss: 0.2357 - val_loss: 0.2525\n",
      "Epoch 99/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 115ms/step - loss: 0.2349 - val_loss: 0.2344\n",
      "Epoch 100/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 102ms/step - loss: 0.2348 - val_loss: 0.2347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x181d086c410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model_1.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "Accuracy: 0.6225\n",
      "Precision: 0.6225\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7673\n"
     ]
    }
   ],
   "source": [
    "#Prever os dados de teste\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_1 = (y_pred_1 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_classes_1)\n",
    "precision_1= precision_score(y_test, y_pred_classes_1)\n",
    "recall_1 = recall_score(y_test, y_pred_classes_1)\n",
    "f1_1 = f1_score(y_test, y_pred_classes_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_1:.4f}\")\n",
    "print(f\"Precision: {precision_1:.4f}\")\n",
    "print(f\"Recall: {recall_1:.4f}\")\n",
    "print(f\"F1-Score: {f1_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40154.000000\n",
       "mean         0.621507\n",
       "std          0.485017\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: S_GROUP_ID_1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"S_GROUP_ID_1\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\Documents\\GitHub\\2024-2A-T08-EC07-G01\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo com GRU\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(GRU(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model_2.add(GRU(50, activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 88ms/step - loss: 0.7814 - val_loss: 0.6714\n",
      "Epoch 2/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - loss: 0.6863 - val_loss: 0.7003\n",
      "Epoch 3/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.6787 - val_loss: 0.6698\n",
      "Epoch 4/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 104ms/step - loss: 0.6726 - val_loss: 0.6631\n",
      "Epoch 5/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 100ms/step - loss: 0.6654 - val_loss: 0.6612\n",
      "Epoch 6/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 88ms/step - loss: 0.6633 - val_loss: 0.6613\n",
      "Epoch 7/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.6740 - val_loss: 0.6691\n",
      "Epoch 8/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 92ms/step - loss: 0.6685 - val_loss: 0.6760\n",
      "Epoch 9/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 99ms/step - loss: 0.6664 - val_loss: 0.6605\n",
      "Epoch 10/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 100ms/step - loss: 0.6638 - val_loss: 0.6699\n",
      "Epoch 11/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 113ms/step - loss: 0.6612 - val_loss: 0.6616\n",
      "Epoch 12/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 90ms/step - loss: 0.6624 - val_loss: 0.6613\n",
      "Epoch 13/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 68ms/step - loss: 0.6590 - val_loss: 0.6625\n",
      "Epoch 14/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 91ms/step - loss: 0.6619 - val_loss: 0.7531\n",
      "Epoch 15/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 87ms/step - loss: 0.6686 - val_loss: 0.6831\n",
      "Epoch 16/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 89ms/step - loss: 0.6687 - val_loss: 0.6637\n",
      "Epoch 17/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 99ms/step - loss: 0.6636 - val_loss: 0.6613\n",
      "Epoch 18/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 94ms/step - loss: 0.6607 - val_loss: 0.6607\n",
      "Epoch 19/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.6631 - val_loss: 0.6627\n",
      "Epoch 20/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 88ms/step - loss: 0.6623 - val_loss: 0.6606\n",
      "Epoch 21/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 90ms/step - loss: 0.6605 - val_loss: 0.6599\n",
      "Epoch 22/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 101ms/step - loss: 0.6633 - val_loss: 0.6622\n",
      "Epoch 23/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 102ms/step - loss: 0.6626 - val_loss: 0.6616\n",
      "Epoch 24/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 105ms/step - loss: 0.6645 - val_loss: 0.6616\n",
      "Epoch 25/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6632 - val_loss: 0.6616\n",
      "Epoch 26/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6636 - val_loss: 0.6616\n",
      "Epoch 27/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6594 - val_loss: 0.6616\n",
      "Epoch 28/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6600 - val_loss: 0.6614\n",
      "Epoch 29/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6634 - val_loss: 0.6613\n",
      "Epoch 30/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6630 - val_loss: 0.6618\n",
      "Epoch 31/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 36ms/step - loss: 0.6632 - val_loss: 0.6617\n",
      "Epoch 32/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - loss: 0.6637 - val_loss: 0.6615\n",
      "Epoch 33/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - loss: 0.6606 - val_loss: 0.6613\n",
      "Epoch 34/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - loss: 0.6616 - val_loss: 0.6611\n",
      "Epoch 35/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - loss: 0.6630 - val_loss: 0.6616\n",
      "Epoch 36/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - loss: 0.6614 - val_loss: 0.6614\n",
      "Epoch 37/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 36ms/step - loss: 0.6613 - val_loss: 0.6610\n",
      "Epoch 38/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 37ms/step - loss: 0.6614 - val_loss: 0.6623\n",
      "Epoch 39/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - loss: 0.6632 - val_loss: 0.6618\n",
      "Epoch 40/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - loss: 0.6641 - val_loss: 0.6619\n",
      "Epoch 41/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - loss: 0.6627 - val_loss: 0.6612\n",
      "Epoch 42/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 44ms/step - loss: 0.6602 - val_loss: 0.6620\n",
      "Epoch 43/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6661 - val_loss: 0.6618\n",
      "Epoch 44/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6630 - val_loss: 0.6615\n",
      "Epoch 45/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6601 - val_loss: 0.6619\n",
      "Epoch 46/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6617 - val_loss: 0.6615\n",
      "Epoch 47/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - loss: 0.6614 - val_loss: 0.6614\n",
      "Epoch 48/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6609 - val_loss: 0.6613\n",
      "Epoch 49/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - loss: 0.6622 - val_loss: 0.6617\n",
      "Epoch 50/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6630 - val_loss: 0.6616\n",
      "Epoch 51/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6627 - val_loss: 0.6615\n",
      "Epoch 52/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6629 - val_loss: 0.6611\n",
      "Epoch 53/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6626 - val_loss: 0.6612\n",
      "Epoch 54/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 52ms/step - loss: 0.6599 - val_loss: 0.6611\n",
      "Epoch 55/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6919 - val_loss: 0.6616\n",
      "Epoch 56/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6630 - val_loss: 0.6615\n",
      "Epoch 57/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 53ms/step - loss: 0.6660 - val_loss: 0.6620\n",
      "Epoch 58/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6629 - val_loss: 0.6617\n",
      "Epoch 59/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6619 - val_loss: 0.6615\n",
      "Epoch 60/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6610 - val_loss: 0.6617\n",
      "Epoch 61/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6633 - val_loss: 0.6617\n",
      "Epoch 62/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6636 - val_loss: 0.6617\n",
      "Epoch 63/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6611 - val_loss: 0.6613\n",
      "Epoch 64/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6619 - val_loss: 0.6618\n",
      "Epoch 65/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6612 - val_loss: 0.6618\n",
      "Epoch 66/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6634 - val_loss: 0.6617\n",
      "Epoch 67/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6649 - val_loss: 0.6617\n",
      "Epoch 68/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6624 - val_loss: 0.6616\n",
      "Epoch 69/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6627 - val_loss: 0.6617\n",
      "Epoch 70/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6615 - val_loss: 0.6617\n",
      "Epoch 71/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6630 - val_loss: 0.6616\n",
      "Epoch 72/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 52ms/step - loss: 0.6617 - val_loss: 0.6616\n",
      "Epoch 73/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6613 - val_loss: 0.6617\n",
      "Epoch 74/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6607 - val_loss: 0.6615\n",
      "Epoch 75/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6642 - val_loss: 0.6618\n",
      "Epoch 76/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6588 - val_loss: 0.6612\n",
      "Epoch 77/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6618 - val_loss: 0.6618\n",
      "Epoch 78/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6614 - val_loss: 0.6619\n",
      "Epoch 79/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6646 - val_loss: 0.6611\n",
      "Epoch 80/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6627 - val_loss: 0.6616\n",
      "Epoch 81/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 50ms/step - loss: 0.6683 - val_loss: 0.6613\n",
      "Epoch 82/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6614 - val_loss: 0.6614\n",
      "Epoch 83/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6601 - val_loss: 0.6613\n",
      "Epoch 84/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6639 - val_loss: 0.6610\n",
      "Epoch 85/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - loss: 0.6625 - val_loss: 0.6611\n",
      "Epoch 86/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6629 - val_loss: 0.6614\n",
      "Epoch 87/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6607 - val_loss: 0.6622\n",
      "Epoch 88/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 53ms/step - loss: 0.6606 - val_loss: 0.6613\n",
      "Epoch 89/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6624 - val_loss: 0.6613\n",
      "Epoch 90/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6628 - val_loss: 0.6610\n",
      "Epoch 91/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6606 - val_loss: 0.6611\n",
      "Epoch 92/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 52ms/step - loss: 0.6631 - val_loss: 0.6614\n",
      "Epoch 93/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6632 - val_loss: 0.6611\n",
      "Epoch 94/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 54ms/step - loss: 0.6635 - val_loss: 0.6609\n",
      "Epoch 95/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - loss: 0.6631 - val_loss: 0.6613\n",
      "Epoch 96/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6626 - val_loss: 0.6615\n",
      "Epoch 97/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6605 - val_loss: 0.6615\n",
      "Epoch 98/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6607 - val_loss: 0.6616\n",
      "Epoch 99/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6622 - val_loss: 0.6613\n",
      "Epoch 100/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6645 - val_loss: 0.6619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x181d6650950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model_2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "Accuracy: 0.6225\n",
      "Precision: 0.6225\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7673\n"
     ]
    }
   ],
   "source": [
    "# Prever os dados de teste\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_2 = (y_pred_2 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_classes_2)\n",
    "precision_2 = precision_score(y_test, y_pred_classes_2)\n",
    "recall_2 = recall_score(y_test, y_pred_classes_2)\n",
    "f1_2 = f1_score(y_test, y_pred_classes_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_2:.4f}\")\n",
    "print(f\"Precision: {precision_2:.4f}\")\n",
    "print(f\"Recall: {recall_2:.4f}\")\n",
    "print(f\"F1-Score: {f1_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos, observamos que tanto os modelos LSTM quanto GRU apresentaram boa performance em termos de recall ao utilizar os dados de torque. No entanto, as demais métricas, como a acurácia, não tiveram o mesmo desempenho, o que nos leva a focar em melhorias nessas áreas. A próxima etapa envolve realizar testes com os dados sem torque e, em seguida, comparar os resultados dos modelos treinados com os dois conjuntos de dados. Isso nos permitirá decidir se devemos ou não manter os dados de torque e, a partir dessa decisão, testar novas técnicas para otimizar o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste com dados de torque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, detalhamos os testes realizados utilizando redes neurais recorrentes LSTM e GRU nos dataframe com dados de torque. O funcionamento dessas técnicas foi explicado em profundidade na documentação da Sprint 2, onde elas foram aplicadas ao modelo principal. Devido ao seu bom desempenho nessa etapa anterior, decidimos iniciar os testes desta Sprint utilizando essas RNNs como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>%</th>\n",
       "      <th>CLICKS</th>\n",
       "      <th>DEG</th>\n",
       "      <th>GRAD</th>\n",
       "      <th>NM</th>\n",
       "      <th>V</th>\n",
       "      <th>\\U00B0</th>\n",
       "      <th>KG</th>\n",
       "      <th>MIN</th>\n",
       "      <th>...</th>\n",
       "      <th>COR_6KA1</th>\n",
       "      <th>COR_6UA1</th>\n",
       "      <th>COR_A1A1</th>\n",
       "      <th>COR_K2A1</th>\n",
       "      <th>COR_K2K2</th>\n",
       "      <th>COR_O7O7</th>\n",
       "      <th>MOTOR_CWL</th>\n",
       "      <th>MOTOR_CWS</th>\n",
       "      <th>MOTOR_DHS</th>\n",
       "      <th>MOTOR_DRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-2016173</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264989</td>\n",
       "      <td>0.074849</td>\n",
       "      <td>0.884665</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-2026098</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462990</td>\n",
       "      <td>0.093920</td>\n",
       "      <td>0.919817</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2026162</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330866</td>\n",
       "      <td>0.094345</td>\n",
       "      <td>0.921463</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-2026175</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436343</td>\n",
       "      <td>0.094345</td>\n",
       "      <td>0.894115</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-2026215</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300888</td>\n",
       "      <td>0.094345</td>\n",
       "      <td>0.911870</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49186</th>\n",
       "      <td>2024-2976009</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195855</td>\n",
       "      <td>0.430977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49187</th>\n",
       "      <td>2024-2976010</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177955</td>\n",
       "      <td>0.429747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49188</th>\n",
       "      <td>2024-2976011</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184092</td>\n",
       "      <td>0.424991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49189</th>\n",
       "      <td>2024-2976012</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192237</td>\n",
       "      <td>0.436295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49190</th>\n",
       "      <td>2024-2976013</td>\n",
       "      <td>0.616167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187182</td>\n",
       "      <td>0.430266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49191 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNR         %  CLICKS  DEG      GRAD        NM         V  \\\n",
       "0      2023-2016173  0.616167     0.0  0.0  0.264989  0.074849  0.884665   \n",
       "1      2023-2026098  0.616167     0.0  0.0  0.462990  0.093920  0.919817   \n",
       "2      2023-2026162  0.616167     0.0  0.0  0.330866  0.094345  0.921463   \n",
       "3      2023-2026175  0.616167     0.0  0.0  0.436343  0.094345  0.894115   \n",
       "4      2023-2026215  0.616167     0.0  0.0  0.300888  0.094345  0.911870   \n",
       "...             ...       ...     ...  ...       ...       ...       ...   \n",
       "49186  2024-2976009  0.616167     0.0  0.0  0.195855  0.430977  0.000000   \n",
       "49187  2024-2976010  0.616167     0.0  0.0  0.177955  0.429747  0.000000   \n",
       "49188  2024-2976011  0.616167     0.0  0.0  0.184092  0.424991  0.000000   \n",
       "49189  2024-2976012  0.616167     0.0  0.0  0.192237  0.436295  0.000000   \n",
       "49190  2024-2976013  0.616167     0.0  0.0  0.187182  0.430266  0.000000   \n",
       "\n",
       "         \\U00B0   KG       MIN  ...  COR_6KA1  COR_6UA1  COR_A1A1  COR_K2A1  \\\n",
       "0      0.470523  0.0  0.811406  ...       NaN       NaN       NaN       NaN   \n",
       "1      0.470523  0.0  0.811406  ...       NaN       NaN       NaN       NaN   \n",
       "2      0.470523  0.0  0.811406  ...       NaN       NaN       NaN       NaN   \n",
       "3      0.470523  0.0  0.811406  ...       NaN       NaN       NaN       NaN   \n",
       "4      0.470523  0.0  0.811406  ...       NaN       NaN       NaN       NaN   \n",
       "...         ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "49186  0.470523  0.0  0.811406  ...       0.0       0.0       0.0       0.0   \n",
       "49187  0.470523  0.0  0.811406  ...       0.0       0.0       0.0       0.0   \n",
       "49188  0.470523  0.0  0.811406  ...       0.0       0.0       0.0       0.0   \n",
       "49189  0.470523  0.0  0.811406  ...       0.0       0.0       0.0       0.0   \n",
       "49190  0.470523  0.0  0.811406  ...       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       COR_K2K2  COR_O7O7  MOTOR_CWL  MOTOR_CWS  MOTOR_DHS  MOTOR_DRP  \n",
       "0           NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "1           NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "2           NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "3           NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "4           NaN       NaN        NaN        NaN        NaN        NaN  \n",
       "...         ...       ...        ...        ...        ...        ...  \n",
       "49186       0.0       0.0        1.0        0.0        0.0        0.0  \n",
       "49187       0.0       0.0        0.0        0.0        1.0        0.0  \n",
       "49188       0.0       0.0        0.0        0.0        1.0        0.0  \n",
       "49189       0.0       0.0        0.0        0.0        1.0        0.0  \n",
       "49190       0.0       0.0        0.0        0.0        1.0        0.0  \n",
       "\n",
       "[49191 rows x 49 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando o dataframe\n",
    "df2 = pd.read_csv(\"../../data/df_torques_falhas.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "49186    1\n",
       "49187    0\n",
       "49188    1\n",
       "49189    1\n",
       "49190    1\n",
       "Name: S_GROUP_ID_1, Length: 49191, dtype: int32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converter a coluna para binário\n",
    "df2['S_GROUP_ID_1'] = (df2['S_GROUP_ID_1'] > 0).astype(int)\n",
    "df2['S_GROUP_ID_1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40152, 49)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluindo as cplunas com dados NaN\n",
    "df2 = df2.dropna()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as features (X) e o target (y)\n",
    "X2 = df2.drop(columns=['S_GROUP_ID_1', 'KNR'])  # 'KNR' é apenas um identificador, então deve ser removido\n",
    "y2 = df2['S_GROUP_ID_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em dados de treino e teste\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte X_train e X_test para arrays NumPy, caso ainda não sejam.\n",
    "X2_train = np.array(X2_train)\n",
    "X2_test = np.array(X2_test)\n",
    "# Reestrutura X_train e X_test para ter 3 dimensões.\n",
    "# A nova forma do array será (n_samples, n_features, 1)\n",
    "X2_train = X2_train.reshape((X2_train.shape[0], X2_train.shape[1], 1))\n",
    "X2_test = X2_test.reshape((X2_test.shape[0], X2_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\Documents\\GitHub\\2024-2A-T08-EC07-G01\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo com LSTM\n",
    "model_1_2 = Sequential()\n",
    "\n",
    "model_1_2.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X2_train.shape[1], 1)))\n",
    "model_1_2.add(LSTM(50, activation='relu'))\n",
    "model_1_2.add(Dense(1))\n",
    "\n",
    "model_1_2.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 113.5401 - val_loss: 10.2416\n",
      "Epoch 2/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 34ms/step - loss: 8.1171 - val_loss: 4.3603\n",
      "Epoch 3/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - loss: 20.1039 - val_loss: 1.4746\n",
      "Epoch 4/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - loss: 1.2708 - val_loss: 0.9603\n",
      "Epoch 5/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - loss: 0.9352 - val_loss: 0.9231\n",
      "Epoch 6/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 72ms/step - loss: 0.9554 - val_loss: 0.6711\n",
      "Epoch 7/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - loss: 0.7078 - val_loss: 0.5205\n",
      "Epoch 8/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - loss: 0.4704 - val_loss: 0.4181\n",
      "Epoch 9/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - loss: 0.3738 - val_loss: 0.3591\n",
      "Epoch 10/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - loss: 0.3463 - val_loss: 0.3918\n",
      "Epoch 11/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 45ms/step - loss: 0.3145 - val_loss: 0.2426\n",
      "Epoch 12/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - loss: 0.2579 - val_loss: 0.2387\n",
      "Epoch 13/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - loss: 0.2536 - val_loss: 0.2378\n",
      "Epoch 14/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.2460 - val_loss: 0.2475\n",
      "Epoch 15/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - loss: 0.2473 - val_loss: 0.2443\n",
      "Epoch 16/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 59ms/step - loss: 0.2465 - val_loss: 0.2397\n",
      "Epoch 17/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 57ms/step - loss: 0.2472 - val_loss: 0.2405\n",
      "Epoch 18/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.2465 - val_loss: 0.2466\n",
      "Epoch 19/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.2435 - val_loss: 0.2350\n",
      "Epoch 20/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 106ms/step - loss: 0.2433 - val_loss: 0.2383\n",
      "Epoch 21/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 100ms/step - loss: 0.2456 - val_loss: 0.2385\n",
      "Epoch 22/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 100ms/step - loss: 0.2398 - val_loss: 0.2360\n",
      "Epoch 23/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 81ms/step - loss: 0.2355 - val_loss: 0.2353\n",
      "Epoch 24/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.2353 - val_loss: 0.2384\n",
      "Epoch 25/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 93ms/step - loss: 0.2365 - val_loss: 0.2365\n",
      "Epoch 26/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 103ms/step - loss: 0.3054 - val_loss: 618.9023\n",
      "Epoch 27/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 90ms/step - loss: 325.1627 - val_loss: 0.2502\n",
      "Epoch 28/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 96ms/step - loss: 0.2552 - val_loss: 0.2385\n",
      "Epoch 29/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - loss: 0.2416 - val_loss: 0.2379\n",
      "Epoch 30/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 85ms/step - loss: 0.2393 - val_loss: 0.2933\n",
      "Epoch 31/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 105ms/step - loss: 0.2448 - val_loss: 0.2358\n",
      "Epoch 32/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - loss: 0.3443 - val_loss: 0.2361\n",
      "Epoch 33/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - loss: 0.2417 - val_loss: 0.2363\n",
      "Epoch 34/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - loss: 0.2465 - val_loss: 0.2423\n",
      "Epoch 35/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - loss: 0.2470 - val_loss: 0.2364\n",
      "Epoch 36/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 44ms/step - loss: 0.2439 - val_loss: 0.2467\n",
      "Epoch 37/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.2474 - val_loss: 0.2411\n",
      "Epoch 38/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - loss: 0.2451 - val_loss: 0.2348\n",
      "Epoch 39/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 45ms/step - loss: 0.2368 - val_loss: 0.2352\n",
      "Epoch 40/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.2345 - val_loss: 0.2350\n",
      "Epoch 41/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.2363 - val_loss: 0.2348\n",
      "Epoch 42/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.2346 - val_loss: 0.2351\n",
      "Epoch 43/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - loss: 0.4738 - val_loss: 0.2350\n",
      "Epoch 44/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - loss: 0.2363 - val_loss: 0.2350\n",
      "Epoch 45/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 90ms/step - loss: 0.2341 - val_loss: 0.2348\n",
      "Epoch 46/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.2360 - val_loss: 0.2347\n",
      "Epoch 47/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2347 - val_loss: 0.2345\n",
      "Epoch 48/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 96ms/step - loss: 0.4666 - val_loss: 0.2354\n",
      "Epoch 49/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 77ms/step - loss: 0.2495 - val_loss: 0.2434\n",
      "Epoch 50/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 63ms/step - loss: 0.2438 - val_loss: 0.2428\n",
      "Epoch 51/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 85ms/step - loss: 0.2418 - val_loss: 0.2345\n",
      "Epoch 52/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 88ms/step - loss: 3574.8777 - val_loss: 0.9854\n",
      "Epoch 53/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 90ms/step - loss: 0.8419 - val_loss: 0.2779\n",
      "Epoch 54/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 1.3396 - val_loss: 122.4725\n",
      "Epoch 55/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 88ms/step - loss: 6.7934 - val_loss: 0.2572\n",
      "Epoch 56/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 100ms/step - loss: 4.8278 - val_loss: 0.2614\n",
      "Epoch 57/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 108ms/step - loss: 0.2537 - val_loss: 0.3131\n",
      "Epoch 58/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 108ms/step - loss: 0.2576 - val_loss: 0.2577\n",
      "Epoch 59/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 113ms/step - loss: 0.2627 - val_loss: 0.2737\n",
      "Epoch 60/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 101ms/step - loss: 0.2677 - val_loss: 0.2465\n",
      "Epoch 61/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.2653 - val_loss: 0.2530\n",
      "Epoch 62/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - loss: 0.2656 - val_loss: 0.2997\n",
      "Epoch 63/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.3506 - val_loss: 0.2377\n",
      "Epoch 64/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 84ms/step - loss: 0.2403 - val_loss: 0.2385\n",
      "Epoch 65/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 80ms/step - loss: 0.2411 - val_loss: 0.2379\n",
      "Epoch 66/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - loss: 0.2492 - val_loss: 0.2575\n",
      "Epoch 67/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - loss: 0.2588 - val_loss: 0.2436\n",
      "Epoch 68/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - loss: 0.2688 - val_loss: 0.2377\n",
      "Epoch 69/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - loss: 0.2711 - val_loss: 0.2592\n",
      "Epoch 70/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 81ms/step - loss: 0.2605 - val_loss: 0.2386\n",
      "Epoch 71/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2504 - val_loss: 0.2913\n",
      "Epoch 72/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 89ms/step - loss: 34.5995 - val_loss: 0.2345\n",
      "Epoch 73/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 90ms/step - loss: 0.2353 - val_loss: 0.2343\n",
      "Epoch 74/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 89ms/step - loss: 0.2374 - val_loss: 0.2386\n",
      "Epoch 75/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 89ms/step - loss: 0.2390 - val_loss: 0.2342\n",
      "Epoch 76/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 89ms/step - loss: 0.2421 - val_loss: 0.2364\n",
      "Epoch 77/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 88ms/step - loss: 0.2354 - val_loss: 0.2346\n",
      "Epoch 78/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2354 - val_loss: 0.2347\n",
      "Epoch 79/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 86ms/step - loss: 0.2351 - val_loss: 0.2347\n",
      "Epoch 80/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2352 - val_loss: 0.2351\n",
      "Epoch 81/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2349 - val_loss: 0.2347\n",
      "Epoch 82/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2360 - val_loss: 0.2346\n",
      "Epoch 83/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - loss: 0.2364 - val_loss: 0.2354\n",
      "Epoch 84/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 86ms/step - loss: 0.2364 - val_loss: 0.2389\n",
      "Epoch 85/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 85ms/step - loss: 0.2348 - val_loss: 0.2348\n",
      "Epoch 86/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2360 - val_loss: 0.2471\n",
      "Epoch 87/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2360 - val_loss: 0.2349\n",
      "Epoch 88/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 86ms/step - loss: 0.2346 - val_loss: 0.2428\n",
      "Epoch 89/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - loss: 0.2363 - val_loss: 0.2348\n",
      "Epoch 90/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 85ms/step - loss: 0.2371 - val_loss: 0.2354\n",
      "Epoch 91/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.2370 - val_loss: 0.2389\n",
      "Epoch 92/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 959.7737 - val_loss: 23.0211\n",
      "Epoch 93/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 14.2422 - val_loss: 3.8826\n",
      "Epoch 94/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 9.7050 - val_loss: 6.9045\n",
      "Epoch 95/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 85ms/step - loss: 1.7229 - val_loss: 0.3104\n",
      "Epoch 96/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.3322 - val_loss: 0.5130\n",
      "Epoch 97/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 87ms/step - loss: 0.2683 - val_loss: 0.2421\n",
      "Epoch 98/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2450 - val_loss: 0.2433\n",
      "Epoch 99/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2513 - val_loss: 0.2413\n",
      "Epoch 100/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 86ms/step - loss: 0.2418 - val_loss: 0.2561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x181f9cc6b50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model_1_2.fit(X2_train, y2_train, epochs=100, batch_size=32, validation_data=(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step\n",
      "Accuracy: 0.6047\n",
      "Precision: 0.6207\n",
      "Recall: 0.9388\n",
      "F1-Score: 0.7473\n"
     ]
    }
   ],
   "source": [
    "#Prever os dados de teste\n",
    "y_pred_1_2 = model_1_2.predict(X2_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_1_2 = (y_pred_1_2 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy = accuracy_score(y2_test, y_pred_classes_1_2)\n",
    "precision = precision_score(y2_test, y_pred_classes_1_2)\n",
    "recall = recall_score(y2_test, y_pred_classes_1_2)\n",
    "f1 = f1_score(y2_test, y_pred_classes_1_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\Documents\\GitHub\\2024-2A-T08-EC07-G01\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo com GRU\n",
    "model_2_2 = Sequential()\n",
    "\n",
    "model_2_2.add(GRU(50, activation='relu', return_sequences=True, input_shape=(X2_train.shape[1], 1)))\n",
    "model_2_2.add(GRU(50, activation='relu'))\n",
    "model_2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2_2.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - loss: 0.6620 - val_loss: 0.6620\n",
      "Epoch 2/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6615 - val_loss: 0.6614\n",
      "Epoch 3/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6966 - val_loss: 0.6960\n",
      "Epoch 4/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 51ms/step - loss: 0.6715 - val_loss: 0.6679\n",
      "Epoch 5/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6617 - val_loss: 0.6621\n",
      "Epoch 6/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6635 - val_loss: 0.6603\n",
      "Epoch 7/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6610 - val_loss: 0.6599\n",
      "Epoch 8/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6629 - val_loss: 0.6622\n",
      "Epoch 9/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6622 - val_loss: 0.6594\n",
      "Epoch 10/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - loss: 0.6585 - val_loss: 0.6593\n",
      "Epoch 11/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6594 - val_loss: 0.6577\n",
      "Epoch 12/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6563 - val_loss: 0.6573\n",
      "Epoch 13/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6580 - val_loss: 0.6547\n",
      "Epoch 14/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 52ms/step - loss: 0.6570 - val_loss: 0.6548\n",
      "Epoch 15/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.6536 - val_loss: 0.6553\n",
      "Epoch 16/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 55ms/step - loss: 0.6524 - val_loss: 0.6547\n",
      "Epoch 17/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6557 - val_loss: 0.6544\n",
      "Epoch 18/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6552 - val_loss: 0.6543\n",
      "Epoch 19/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 53ms/step - loss: 0.6503 - val_loss: 0.6548\n",
      "Epoch 20/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6496 - val_loss: 0.6534\n",
      "Epoch 21/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 53ms/step - loss: 0.6517 - val_loss: 0.6546\n",
      "Epoch 22/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6553 - val_loss: 0.6571\n",
      "Epoch 23/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6521 - val_loss: 0.6528\n",
      "Epoch 24/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - loss: 0.6485 - val_loss: 0.6531\n",
      "Epoch 25/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6485 - val_loss: 0.6527\n",
      "Epoch 26/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6496 - val_loss: 0.6558\n",
      "Epoch 27/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.6491 - val_loss: 0.6529\n",
      "Epoch 28/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - loss: 0.6514 - val_loss: 0.6534\n",
      "Epoch 29/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6484 - val_loss: 0.6526\n",
      "Epoch 30/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6473 - val_loss: 0.6542\n",
      "Epoch 31/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6477 - val_loss: 0.6521\n",
      "Epoch 32/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6464 - val_loss: 0.6523\n",
      "Epoch 33/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6508 - val_loss: 0.6515\n",
      "Epoch 34/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 46ms/step - loss: 0.6451 - val_loss: 0.6503\n",
      "Epoch 35/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6444 - val_loss: 0.6511\n",
      "Epoch 36/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6441 - val_loss: 0.6514\n",
      "Epoch 37/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 51ms/step - loss: 0.6444 - val_loss: 0.6559\n",
      "Epoch 38/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6459 - val_loss: 0.6531\n",
      "Epoch 39/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6505 - val_loss: 0.6535\n",
      "Epoch 40/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6448 - val_loss: 0.6501\n",
      "Epoch 41/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 63ms/step - loss: 0.6455 - val_loss: 0.6524\n",
      "Epoch 42/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 88ms/step - loss: 0.6488 - val_loss: 0.6514\n",
      "Epoch 43/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 89ms/step - loss: 0.6414 - val_loss: 0.6520\n",
      "Epoch 44/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 89ms/step - loss: 0.6450 - val_loss: 0.6535\n",
      "Epoch 45/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 65ms/step - loss: 0.6434 - val_loss: 0.6555\n",
      "Epoch 46/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6440 - val_loss: 0.6517\n",
      "Epoch 47/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6407 - val_loss: 0.6497\n",
      "Epoch 48/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 77ms/step - loss: 0.6426 - val_loss: 0.6517\n",
      "Epoch 49/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 92ms/step - loss: 0.6403 - val_loss: 0.6551\n",
      "Epoch 50/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - loss: 0.6413 - val_loss: 0.6506\n",
      "Epoch 51/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6362 - val_loss: 0.6504\n",
      "Epoch 52/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6389 - val_loss: 0.6624\n",
      "Epoch 53/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 52ms/step - loss: 0.6480 - val_loss: 0.6521\n",
      "Epoch 54/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6395 - val_loss: 0.6553\n",
      "Epoch 55/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.6411 - val_loss: 0.6569\n",
      "Epoch 56/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.6401 - val_loss: 0.6510\n",
      "Epoch 57/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6384 - val_loss: 0.6541\n",
      "Epoch 58/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - loss: 0.6369 - val_loss: 0.6529\n",
      "Epoch 59/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6377 - val_loss: 0.6521\n",
      "Epoch 60/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6373 - val_loss: 0.6519\n",
      "Epoch 61/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 0.6367 - val_loss: 0.6510\n",
      "Epoch 62/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6384 - val_loss: 0.6536\n",
      "Epoch 63/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6453 - val_loss: 0.6658\n",
      "Epoch 64/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6572 - val_loss: 0.6518\n",
      "Epoch 65/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6420 - val_loss: 0.6493\n",
      "Epoch 66/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6381 - val_loss: 0.6492\n",
      "Epoch 67/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6370 - val_loss: 0.6511\n",
      "Epoch 68/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.6388 - val_loss: 0.6509\n",
      "Epoch 69/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6352 - val_loss: 0.6534\n",
      "Epoch 70/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6402 - val_loss: 0.6639\n",
      "Epoch 71/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6621 - val_loss: 0.6591\n",
      "Epoch 72/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - loss: 0.6596 - val_loss: 0.6597\n",
      "Epoch 73/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6557 - val_loss: 0.6590\n",
      "Epoch 74/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - loss: 0.6583 - val_loss: 0.6545\n",
      "Epoch 75/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6553 - val_loss: 0.6560\n",
      "Epoch 76/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 0.6537 - val_loss: 0.6567\n",
      "Epoch 77/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - loss: 0.6571 - val_loss: 0.6591\n",
      "Epoch 78/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 48ms/step - loss: 0.6542 - val_loss: 0.6573\n",
      "Epoch 79/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - loss: 0.6557 - val_loss: 0.6557\n",
      "Epoch 80/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 90ms/step - loss: 0.6580 - val_loss: 0.6582\n",
      "Epoch 81/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 89ms/step - loss: 0.6575 - val_loss: 0.6567\n",
      "Epoch 82/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 89ms/step - loss: 0.6562 - val_loss: 0.6559\n",
      "Epoch 83/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 90ms/step - loss: 0.6556 - val_loss: 0.6546\n",
      "Epoch 84/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 89ms/step - loss: 0.6517 - val_loss: 0.6568\n",
      "Epoch 85/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 92ms/step - loss: 0.6555 - val_loss: 0.6582\n",
      "Epoch 86/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 96ms/step - loss: 0.6560 - val_loss: 0.6563\n",
      "Epoch 87/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 93ms/step - loss: 0.6540 - val_loss: 0.6567\n",
      "Epoch 88/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 93ms/step - loss: 0.6527 - val_loss: 0.6540\n",
      "Epoch 89/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 92ms/step - loss: 0.6519 - val_loss: 0.6550\n",
      "Epoch 90/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 86ms/step - loss: 0.6546 - val_loss: 0.6537\n",
      "Epoch 91/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 87ms/step - loss: 0.6506 - val_loss: 0.6640\n",
      "Epoch 92/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 87ms/step - loss: 0.6584 - val_loss: 0.6596\n",
      "Epoch 93/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 80ms/step - loss: 0.7004 - val_loss: 0.6616\n",
      "Epoch 94/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.6728 - val_loss: 0.6642\n",
      "Epoch 95/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - loss: 0.6633 - val_loss: 0.6656\n",
      "Epoch 96/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - loss: 0.6679 - val_loss: 0.6622\n",
      "Epoch 97/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - loss: 0.6657 - val_loss: 0.6673\n",
      "Epoch 98/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 29ms/step - loss: 0.6675 - val_loss: 0.6645\n",
      "Epoch 99/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 35ms/step - loss: 0.6643 - val_loss: 0.6622\n",
      "Epoch 100/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.6590 - val_loss: 0.6605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1820754f410>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model_2_2.fit(X2_train, y2_train, epochs=100, batch_size=32, validation_data=(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "Accuracy: 0.6226\n",
      "Precision: 0.6227\n",
      "Recall: 0.9994\n",
      "F1-Score: 0.7673\n"
     ]
    }
   ],
   "source": [
    "# Prever os dados de teste\n",
    "y_pred_2_2 = model_2_2.predict(X2_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_2_2 = (y_pred_2_2 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy = accuracy_score(y2_test, y_pred_classes_2_2)\n",
    "precision = precision_score(y2_test, y_pred_classes_2_2)\n",
    "recall = recall_score(y2_test, y_pred_classes_2_2)\n",
    "f1 = f1_score(y2_test, y_pred_classes_2_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos, observamos que tanto os modelos LSTM quanto GRU tiveram um bom desempenho em termos de recall ao utilizar os dados de torque. No entanto, outras métricas, como a acurácia, não apresentaram o mesmo nível de performance, tanto com os dados de torque quanto com o dataframe sem esses dados. Ao comparar os dois dataframes, notamos que ambos tiveram um desempenho muito similar, o que indica que ambos podem ser utilizados nos modelos. No entanto, para os próximos testes, optamos por trabalhar com o dataframe que inclui os dados de torque, pois ele apresentou métricas mais consistentes e fornece um conjunto mais rico de features.\n",
    "\n",
    "Para melhorar as métricas observadas, aplicaremos as seguintes técnicas:\n",
    "\n",
    "- Diferentes testes de balanceamento \n",
    "- Teste de outros tipos de modelos.\n",
    "- Revisão e aprimoramento do tratamento dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Últimos teste realizados nessa Sprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ainda essa Sprint, realizamos testes com o balanceamento por undersampling com clusterização, utilizando os centróides de cada cluster. Utilizamos essa tecnica a partir do código abaixo, utilizando X2_balanced e y2_balanced para treinar e aplicar os modelos GRU e LSTM. Entretanto, as métricas diminuiram drasticamente, indicando que devem ser realizadas melhorias ou na forma de balanceamento, ou no tramaento dos dados que estamos utilizando. Para averiguar, basta utilizar o código a seguir antes do treinamento e aplicação dos modelos na etapa de testes com dados de torque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as classes majoritária e minoritária com base no target y2\n",
    "X2_majority = X2[y2 == 0]\n",
    "X2_minority = X2[y2 == 1]\n",
    "\n",
    "# Definindo o número de clusters como o tamanho da classe minoritária\n",
    "n_clusters = len(X2_minority)\n",
    "\n",
    "# Aplicando o K-Means à classe majoritária\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "kmeans.fit(X2_majority)\n",
    "\n",
    "# Pegando os centróides dos clusters\n",
    "X2_majority_centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Combinando os centróides com a classe minoritária\n",
    "X2_balanced = np.vstack((X2_majority_centroids, X2_minority))\n",
    "y2_balanced = np.hstack((np.zeros(len(X2_majority_centroids)), np.ones(len(X2_minority))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, tentamos também aplicar a seguinte rede neural convolucional, para testar a performance do modelo. Infelizmente, não obtivemos resultados tão positivos quanto os dos modelo GRU e LSTM, porém, pretendemos focar em pesquisar e aplicar novos tipos de rede neural convolucional que possam se adequar melhor ao problema e trazer melhores resultados na próxima Sprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\Documents\\GitHub\\2024-2A-T08-EC07-G01\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definir o modelo CNN\n",
    "model_3 = Sequential()\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X2_train.shape[1], 1)))\n",
    "model_3.add(MaxPooling1D(pool_size=2))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model_3.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "model_3.add(MaxPooling1D(pool_size=2))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "# Flatten para converter dados 2D em 1D\n",
    "model_3.add(Flatten())\n",
    "\n",
    "# Camada totalmente conectada\n",
    "model_3.add(Dense(64, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "# Camada de saída para classificação binária\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilação do modelo\n",
    "model_3.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5820 - loss: 2.2350 - val_accuracy: 0.6227 - val_loss: 0.6653\n",
      "Epoch 2/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6247 - loss: 0.6663 - val_accuracy: 0.6227 - val_loss: 0.6625\n",
      "Epoch 3/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6262 - loss: 0.6614 - val_accuracy: 0.6227 - val_loss: 0.6625\n",
      "Epoch 4/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 0.6638 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 5/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.6660 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 6/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 0.6619 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 7/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6228 - loss: 0.6640 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 8/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6212 - loss: 0.6665 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 9/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6650 - val_accuracy: 0.6227 - val_loss: 0.6621\n",
      "Epoch 10/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6198 - loss: 0.6669 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 11/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6192 - loss: 0.6650 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 12/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6178 - loss: 0.6655 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 13/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6233 - loss: 0.6623 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 14/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.6632 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 15/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6239 - loss: 0.6620 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 16/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6171 - loss: 0.6653 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 17/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 0.6640 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 18/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6188 - loss: 0.6646 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 19/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6248 - loss: 0.6616 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 20/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6198 - loss: 0.6639 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 21/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 0.6639 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 22/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.6630 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 23/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 0.6617 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 24/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.6608 - val_accuracy: 0.6227 - val_loss: 0.6626\n",
      "Epoch 25/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6235 - loss: 0.6627 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 26/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 0.6615 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 27/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6247 - loss: 0.6617 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 28/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.6624 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 29/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6207 - loss: 0.6636 - val_accuracy: 0.6227 - val_loss: 0.6621\n",
      "Epoch 30/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6220 - loss: 0.6640 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 31/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6224 - loss: 0.6629 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 32/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6260 - loss: 0.6610 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 33/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 0.6641 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 34/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6175 - loss: 0.6650 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 35/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6243 - loss: 0.6617 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 36/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6220 - loss: 0.6632 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 37/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6235 - loss: 0.6630 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 38/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6201 - loss: 0.6639 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 39/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6187 - loss: 0.6645 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 40/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.6660 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 41/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6195 - loss: 0.6643 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 42/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.6633 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 43/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 0.6651 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 44/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 0.6641 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 45/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6216 - loss: 0.6631 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 46/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 0.6631 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 47/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.6627 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 48/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6238 - loss: 0.6621 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 49/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 0.6638 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 50/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6258 - loss: 0.6610 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 51/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 0.6648 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 52/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.6622 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 53/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6199 - loss: 0.6640 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 54/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 0.6646 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 55/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6224 - loss: 0.6626 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 56/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.6632 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 57/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6207 - loss: 0.6636 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 58/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6187 - loss: 0.6648 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 59/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6231 - loss: 0.6628 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 60/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 0.6633 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 61/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 0.6638 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 62/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.6640 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 63/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: 0.6603 - val_accuracy: 0.6227 - val_loss: 0.6625\n",
      "Epoch 64/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6181 - loss: 0.6647 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 65/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6279 - loss: 0.6599 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 66/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 0.6653 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 67/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6225 - loss: 0.6627 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 68/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.6638 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 69/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.6643 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 70/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.6631 - val_accuracy: 0.6227 - val_loss: 0.6621\n",
      "Epoch 71/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6205 - loss: 0.6636 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 72/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6182 - loss: 0.6649 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 73/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6217 - loss: 0.6631 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 74/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6221 - loss: 0.6630 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 75/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 0.6638 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 76/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.6635 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 77/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6238 - loss: 0.6626 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 78/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6172 - loss: 0.6653 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 79/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 0.6637 - val_accuracy: 0.6227 - val_loss: 0.6621\n",
      "Epoch 80/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6203 - loss: 0.6650 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 81/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6188 - loss: 0.6646 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 82/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6182 - loss: 0.6649 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 83/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6227 - loss: 0.6626 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 84/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 0.6652 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 85/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6189 - loss: 0.6645 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 86/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 0.6612 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 87/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.6633 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 88/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6191 - loss: 0.6645 - val_accuracy: 0.6227 - val_loss: 0.6622\n",
      "Epoch 89/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6178 - loss: 0.6650 - val_accuracy: 0.6227 - val_loss: 0.6621\n",
      "Epoch 90/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.6626 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 91/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6156 - loss: 0.6662 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 92/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6249 - loss: 0.6615 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 93/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 0.6636 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 94/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6237 - loss: 0.6622 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 95/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6225 - loss: 0.6627 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 96/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 0.6648 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 97/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6167 - loss: 0.6662 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 98/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 0.6635 - val_accuracy: 0.6227 - val_loss: 0.6624\n",
      "Epoch 99/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 0.6639 - val_accuracy: 0.6227 - val_loss: 0.6623\n",
      "Epoch 100/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6223 - loss: 0.6626 - val_accuracy: 0.6227 - val_loss: 0.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x182116c4e50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model_3.fit(X2_train, y2_train, epochs=100, batch_size=32, validation_data=(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.6227\n",
      "Precision: 0.6227\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.7675\n"
     ]
    }
   ],
   "source": [
    "# Prever os dados de teste\n",
    "y_pred_3 = model_3.predict(X2_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_3 = (y_pred_3 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy = accuracy_score(y2_test, y_pred_classes_3)\n",
    "precision = precision_score(y2_test, y_pred_classes_3)\n",
    "recall = recall_score(y2_test, y_pred_classes_3)\n",
    "f1 = f1_score(y2_test, y_pred_classes_3)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
